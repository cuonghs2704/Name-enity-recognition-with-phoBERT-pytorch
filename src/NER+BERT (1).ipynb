{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Cài các thư viện "
      ],
      "metadata": {
        "id": "M-4iJW_-WWqq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "isgW9QK-lyZN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21f1a4fd-4727-4d14-d5c9-6f68b4c3aefe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-crf\n",
            "  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0+cu116)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install pytorch-crf\n",
        "!pip install torchmetrics\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset : \n",
        "- Sử dụng API tokenizer có sẵn \n",
        "- chuẩn hóa, vector hóa dữ liệu "
      ],
      "metadata": {
        "id": "hRH6dMsKWacX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gM-IqyFhl2EN"
      },
      "outputs": [],
      "source": [
        "\n",
        "#API\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
        "\"\"\"\n",
        "class Build_Vocab():\n",
        "  def __init__(self, file1, file2):\n",
        "    f1 = open(file1)\n",
        "    f2 = open(file2)\n",
        "    rows1 = f1.readlines()\n",
        "    rows2 = f2.readlines()\n",
        "    rows = rows1 + rows2\n",
        "    self.maxlen = 75\n",
        "   \n",
        "    tokenizer = Tokenizer(oov_token = '<oov>')\n",
        "    tokenizer.fit_on_texts([[i.split()[0]] for i in rows if i != '\\n'])\n",
        "    self.vocab = tokenizer.word_index\n",
        "    self.vocab_reverse = {}\n",
        "    for key, value in tokenizer.word_index.items():\n",
        "      self.vocab_reverse[value] = key\n",
        "    self.vocab_reverse[0] = ''\n",
        "  def __len__(self):\n",
        "    return len(self.vocab)\n",
        "\"\"\"\n",
        "class Dataset():\n",
        "  def __init__(self, file, max_len=160):\n",
        "    f = open(file)\n",
        "    rows = f.readlines()\n",
        "    self.maxlen = max_len\n",
        "    self.data = {\n",
        "        \"sentences\" : [],\n",
        "        \"labels\" : []\n",
        "    }\n",
        "   \n",
        "    sentence = []\n",
        "    label = []\n",
        "    for row in rows:\n",
        "      if row == '\\n':\n",
        "        self.data[\"sentences\"].append(sentence)\n",
        "        self.data[\"labels\"].append(label)\n",
        "       \n",
        "        sentence = []\n",
        "        label = []\n",
        "      else:  \n",
        "        list_row = row.split() \n",
        "        sentence.append(list_row[0])\n",
        "        label.append(list_row[1])\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    \n",
        "    sent =  self.data[\"sentences\"][i]\n",
        "    \n",
        "    #padding câu \n",
        "    sent_pad = pad_sequences([sent], self.maxlen, object, padding='post', value='<pad>')\n",
        "    sent = \" \".join(sent)\n",
        "    seq = tokenizer.encode(sent)[1:-1]\n",
        "\n",
        "    seq_pad =  pad_sequences([seq], self.maxlen, padding='post', value=1.0)\n",
        "    tag = self.data[\"labels\"][i]\n",
        "\n",
        "    #padding tags\n",
        "    tags_pad = pad_sequences([tag], self.maxlen, object, padding='post', value='pad')[0]\n",
        "    tags = []\n",
        "    tags_number = []\n",
        "    tags_number_nonPad = []\n",
        "    for i in range(len(tags_pad)):\n",
        "      tags.append(One_Hot(tags_pad[i]))\n",
        "      tags_number.append(normLabel(tags_pad[i]))\n",
        "  \n",
        "     \n",
        "  \n",
        "    return {\n",
        "        \"sentences\": \" \".join(sent_pad[0]),\n",
        "        \"sequences\": np.array(seq_pad[0]),\n",
        "        \"tags\": np.array(tags),\n",
        "        \"tags_number\": np.array(tags_number),\n",
        "       \n",
        "    }\n",
        "  def __len__(self):\n",
        "    return len(self.data[\"sentences\"])\n",
        "l = [\"O\", \"B-LOCATION\", \"I-LOCATION\", \"B-PATIENT_ID\", \"I-PATIENT_ID\", \n",
        "       \"B-ORGANIZATION\", \"I-ORGANIZATION\", \n",
        "       \"I-SYMPTOM_AND_DISEASE\", \"B-SYMPTOM_AND_DISEASE\", \n",
        "       \"B-NAME\",\"I-JOB\",\"B-JOB\",\n",
        "       \"B-DATE\", \"I-DATE\", \"B-TRANSPORTATION\",\n",
        "       \"B-AGE\", \"B-GENDER\", \"PAD\"]\n",
        "def normLabel(label):\n",
        "  try:\n",
        "    return l.index(label)\n",
        "    \n",
        "  except:\n",
        "    return len(l)\n",
        "    \n",
        "def One_Hot(label):\n",
        "  seq = np.zeros(len(l) + 1)\n",
        "  try:\n",
        "    #return l.index(label)\n",
        "    seq[l.index(label)] = 1\n",
        "    return seq\n",
        "  except:\n",
        "    #return l.index('O')\n",
        "    seq[len(l)] = 1\n",
        "    return seq\n",
        "\n",
        "TAG_SIZE = len(l)\n",
        "PATH_TRAIN = \"/content/drive/MyDrive/Cuongdb/DataNLP/train_word.txt\"\n",
        "PATH_TEST = \"/content/drive/MyDrive/Cuongdb/DataNLP/test_word.txt\"\n",
        "dataset = Dataset(PATH_TRAIN)\n",
        "dataset_val = Dataset(PATH_TEST)\n",
        "from torch.utils.data import DataLoader \n",
        "dataloader = DataLoader(dataset, batch_size = 128)\n",
        "dataloader_val = DataLoader(dataset_val, batch_size = 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MẪU DATASET "
      ],
      "metadata": {
        "id": "1Zis4uH0XMzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndYwSHQeGYI2",
        "outputId": "b4211d12-4d37-484c-f2b6-1a61ee3c2e9f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentences': 'Đồng_thời , bệnh_viện tiếp_tục thực_hiện các biện_pháp phòng_chống dịch_bệnh COVID - 19 theo hướng_dẫn của Bộ Y_tế . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>',\n",
              " 'sequences': array([1248,    4,  757,  194,  112,    9,  717, 2137, 3795, 9089, 6232,\n",
              "        1927,   31, 1195,   63, 1010,    7,  125, 1059,    5,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1], dtype=int32),\n",
              " 'tags': array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 1.],\n",
              "        [0., 0., 0., ..., 0., 0., 1.],\n",
              "        [0., 0., 0., ..., 0., 0., 1.]]),\n",
              " 'tags_number': array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  5,  6,\n",
              "         0, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "        18, 18, 18, 18, 18, 18, 18])}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MZHYdJzqUXm"
      },
      "source": [
        "# MODEL PRE_TRAIN WITH CRFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LD2LduxrqT4W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "a18e349ca4d642d4951db883e2b86691",
            "2d56c97c75f34896bedf07e5463bca3a",
            "3fe75a42bddb4f05b12b6ad4d06638c4",
            "a61f02c6ab304681959c3ec72795ede2",
            "59c5be1991f2443fb1001b06148aff3b",
            "60eb01cfc491435295323dbeb9f5c287",
            "651d3240c9674d948adb31b5edee942c",
            "52a79ac3e0a84c6dab877e928d8a4c99",
            "289fcada658048a98c2d5100e04b1cf1",
            "d0e25584ceb14307b6bbc96c846ca7bb",
            "d7f1cac662a2408f9058cb80e345312c"
          ]
        },
        "outputId": "45e278c5-6406-46c7-f6af-6f8e4f4482e2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/543M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a18e349ca4d642d4951db883e2b86691"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1e8f2491Gyu"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torchcrf import CRF\n",
        "TAG_SIZE = 19\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "class NERbert(nn.Module):\n",
        "  def __init__(self, pre_train, n_dim, num_tags):\n",
        "    super().__init__()\n",
        "    self.BERT = pre_train\n",
        "    for child in self.BERT.children():\n",
        "      for param in child.parameters():\n",
        "          param.requires_grad = False\n",
        "    self.fc = nn.Linear(n_dim, num_tags)\n",
        "    self.crf = CRF(num_tags, batch_first=True)\n",
        "  def forward(self, x, tags=None, pad_id=1):\n",
        "    x_masks = self.make_bert_mask(x, pad_id)  # (B, L)\n",
        "    \n",
        "    features = self.BERT(x, attention_mask=x_masks)[0] #(B, L, N_dim) , (B, N_dim)\n",
        "\n",
        "    #(B, L, N) = feature.size()\n",
        "    output = self.fc(features) #(B, L, N_tag)\n",
        " \n",
        "    #print(output.shape[:2], tags.shape, x_masks.shape)\n",
        "    if tags is not None:\n",
        "      log_likelihood = self.crf(output, tags, mask=x_masks.bool(), reduction='mean')\n",
        "    else:\n",
        "      log_likelihood = None\n",
        "    sequence_of_tags = self.crf.decode(output, mask=x_masks.bool())\n",
        "    #return log_likelihood, sequence_of_tags\n",
        "    \n",
        "    sequence_of_tags = pad_sequences(sequence_of_tags, maxlen=x.size()[1], padding=\"post\", value = 18)\n",
        "    if tags is not None :\n",
        "      return torch.Tensor(log_likelihood), torch.Tensor(sequence_of_tags)  # (), (B, L)\n",
        "    else :\n",
        "      return torch.Tensor(sequence_of_tags)\n",
        "    \n",
        "  def make_bert_mask(self, x, pad_id):\n",
        "    bert_masks = (x != pad_id).float()  # (B, L)\n",
        "    return torch.Tensor(bert_masks)\n",
        "model = NERbert(phobert, 768, TAG_SIZE)\n",
        "model = model.to(device)\n",
        "\"\"\"\n",
        "input = torch.Tensor([dataset[0][\"sequences\"]]).to(torch.int64)\n",
        "tags = torch.Tensor([dataset[0][\"tags_number\"]]).to(torch.int64)\n",
        "loss,output = model(input, tags)\n",
        "\n",
        "\"\"\"\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=0.01)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "J52kt3S1J6gh",
        "outputId": "5008b5f2-16b8-4d5f-f03e-25edb1238727",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NERbert(\n",
            "  (BERT): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): RobertaPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=768, out_features=19, bias=True)\n",
            "  (crf): CRF(num_tags=19)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAQw3-178gbi"
      },
      "outputs": [],
      "source": [
        "from transformers.modeling_tf_utils import input_processing\n",
        "from torchmetrics import F1Score\n",
        "f1 = F1Score(task=\"multiclass\", num_classes=len(l))\n",
        "f1.to(device)\n",
        "def f1_function(o, t, len = 160):\n",
        "  o1_pad = pad_sequences(o, maxlen = len, padding = \"post\", value = 18)\n",
        "  p1 = f1(o1_pad, t)\n",
        "  print(o1_pad)\n",
        "  o2_pad = pad_sequences(o, maxlen = len, padding = \"post\", value = 19)\n",
        "  p2 = f1(o2_pad, t)\n",
        "  print(o2_pad)\n",
        "  return p2 / (1-p1-p2)\n",
        "def train(model, device, optim, dataloader):\n",
        "    total_loss = 0\n",
        "    f1_score = 0\n",
        "    id_pad = 18\n",
        "    model.train()\n",
        "    for i, batch in enumerate(dataloader):\n",
        "      inputs = batch[\"sequences\"].to(device)\n",
        "      tags = batch[\"tags_number\"].to(device)\n",
        "   \n",
        "      log_loss, outputs = model(inputs, tags)\n",
        "      outputs = outputs.to(device)\n",
        "      f1_score += f1(outputs, tags)\n",
        "      loss = -1 * log_loss\n",
        "      model.zero_grad()\n",
        "      optim.zero_grad()\n",
        "      loss.backward()\n",
        "      optim.step()   \n",
        "      total_loss += loss.detach().item()\n",
        "    return total_loss/len(dataloader), f1_score/(len(dataloader)), model\n",
        "def validation(model, device, dataloader):\n",
        "  total_loss_val = 0\n",
        "  model.eval()\n",
        "  f1_score = 0\n",
        "  with torch.no_grad():\n",
        "    for i, batch in enumerate(dataloader):\n",
        "      inputs = batch[\"sequences\"].to(device)\n",
        "      tags = batch[\"tags_number\"].to(device)\n",
        " \n",
        "      log_loss, outputs = model(inputs, tags)\n",
        "      outputs = outputs.to(device)\n",
        "      f1_score += f1(outputs, tags)\n",
        "      loss_val = -1 * log_loss\n",
        "      total_loss_val += loss_val.detach().item()\n",
        "  return total_loss_val/len(dataloader), f1_score/(len(dataloader))\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_z0dhRmAzPG5"
      },
      "outputs": [],
      "source": [
        "def train_val(model, device, epochs, optim, dataloader, dataloader_val):\n",
        "  best_loss = np.Inf \n",
        "  PATH = \"/content/drive/MyDrive/Cuongdb/NerBer2.pth\"\n",
        "  for epoch in range(epochs):\n",
        "    print(\"#\"*50 + f\" Epoch: {epoch} \" + \"#\"*50)\n",
        "    loss_train, f1, model_trained = train(model, device, optim, dataloader)\n",
        "    loss_val, f1_val = validation(model_trained, device, dataloader_val)\n",
        "    if best_loss > loss_val:\n",
        "      best_loss = loss_val\n",
        "      torch.save(model_trained, PATH)\n",
        "    print(f\"loss : {loss_train}  -  f1 : {f1}  -   loss_val : {loss_val}   -  f1_val = {f1_val}\")\n",
        "  return model_trained\n",
        "train_val(model, device, 200, optim, dataloader, dataloader_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_JldfYX7NJw"
      },
      "outputs": [],
      "source": [
        "bermodel = NERbert(phobert, 768, TAG_SIZE)\n",
        "bermodel = torch.load(\"/content/drive/MyDrive/Cuongdb/NerBer.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = 2\n",
        "input = torch.tensor([dataset_val[ids][\"sequences\"]]).to(device)\n",
        "tag = torch.zeros((1,160)).to(torch.int64).to(device) #torch.tensor([dataset_val[ids][\"tags_number\"]]).to(device)\n",
        "_, output = bermodel(input, tag)\n",
        "for i in range(len(output[0])):\n",
        "  id = int(input[0][i].cpu().detach().numpy())\n",
        "  id_o = int(output[0][i].cpu().detach().numpy())\n",
        "  if id != 1:\n",
        "    print(tokenizer.convert_ids_to_tokens(id), l[id_o])\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "759DTLe2EetX",
        "outputId": "53c4a9d2-3bea-4a00-b9aa-d0c49b5f1307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theo O\n",
            "đó O\n",
            ", O\n",
            "Sở B-ORGANIZATION\n",
            "Y_tế I-ORGANIZATION\n",
            "Bình_Thuận I-ORGANIZATION\n",
            "cho O\n",
            "biết O\n",
            "sau O\n",
            "khi O\n",
            "xác_định O\n",
            "bệnh_nhân O\n",
            "số O\n",
            "34 B-PATIENT_ID\n",
            "( O\n",
            "nữ_giới O\n",
            "51 O\n",
            "tuổi O\n",
            ", O\n",
            "từ O\n",
            "Mỹ B-LOCATION\n",
            "về O\n",
            "Việt_Nam O\n",
            "ngày O\n",
            "29 B-DATE\n",
            "- I-DATE\n",
            "2 I-DATE\n",
            "có O\n",
            "quá_cảnh O\n",
            "Qatar O\n",
            ") O\n",
            ", O\n",
            "Trung_tâm B-ORGANIZATION\n",
            "Kiểm_soát I-ORGANIZATION\n",
            "bệnh_tật I-ORGANIZATION\n",
            "Bình_Thuận I-ORGANIZATION\n",
            "đã O\n",
            "điều_tra O\n",
            "dịch_tễ O\n",
            ", O\n",
            "khoanh O\n",
            "vùng O\n",
            ", O\n",
            "khử O\n",
            "khuẩn O\n",
            ", O\n",
            "tiến_hành O\n",
            "cách_ly O\n",
            "người O\n",
            "liên_quan O\n",
            "đến O\n",
            "ca O\n",
            "bệnh O\n",
            "số O\n",
            "34 B-PATIENT_ID\n",
            ". O\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a18e349ca4d642d4951db883e2b86691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d56c97c75f34896bedf07e5463bca3a",
              "IPY_MODEL_3fe75a42bddb4f05b12b6ad4d06638c4",
              "IPY_MODEL_a61f02c6ab304681959c3ec72795ede2"
            ],
            "layout": "IPY_MODEL_59c5be1991f2443fb1001b06148aff3b"
          }
        },
        "2d56c97c75f34896bedf07e5463bca3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60eb01cfc491435295323dbeb9f5c287",
            "placeholder": "​",
            "style": "IPY_MODEL_651d3240c9674d948adb31b5edee942c",
            "value": "Downloading: 100%"
          }
        },
        "3fe75a42bddb4f05b12b6ad4d06638c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52a79ac3e0a84c6dab877e928d8a4c99",
            "max": 542923308,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_289fcada658048a98c2d5100e04b1cf1",
            "value": 542923308
          }
        },
        "a61f02c6ab304681959c3ec72795ede2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0e25584ceb14307b6bbc96c846ca7bb",
            "placeholder": "​",
            "style": "IPY_MODEL_d7f1cac662a2408f9058cb80e345312c",
            "value": " 543M/543M [00:07&lt;00:00, 66.6MB/s]"
          }
        },
        "59c5be1991f2443fb1001b06148aff3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60eb01cfc491435295323dbeb9f5c287": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "651d3240c9674d948adb31b5edee942c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52a79ac3e0a84c6dab877e928d8a4c99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "289fcada658048a98c2d5100e04b1cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0e25584ceb14307b6bbc96c846ca7bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7f1cac662a2408f9058cb80e345312c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}